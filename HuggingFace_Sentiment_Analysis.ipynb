{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkZQNZhSEk8bf1K1BlS3o/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelVieira13/Hugging_Face_Tutorial/blob/main/HuggingFace_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HuggingFACE Crash Course\n",
        "https://www.youtube.com/watch?v=GSt00_-0ncQ"
      ],
      "metadata": {
        "id": "vDEBWlY4nei-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "I0Vfjhatto2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Pipelines\n",
        "* https://huggingface.co/transformers/v3.0.2/main_classes/pipelines.html"
      ],
      "metadata": {
        "id": "k_uN4-eXnlWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis using the default model\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "results = classifier([\"Today I'm feeling sleepy\",\n",
        "                 \"Today I'm feeling great\"])\n",
        "\n",
        "for result in results:\n",
        "  print(result['label'], result['score'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic7aU0c9nyC4",
        "outputId": "a1513007-a297-4754-dd7f-1e5d60bc4dad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEGATIVE 0.9985528588294983\n",
            "POSITIVE 0.9998780488967896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Model and Tokenization"
      ],
      "metadata": {
        "id": "PizxJxt0sBFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis using a specific model\n",
        "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model = model, tokenizer=tokenizer)\n",
        "results = classifier([\"Today I'm feeling sleepy\",\n",
        "                 \"Today I'm feeling great\"])\n",
        "\n",
        "for result in results:\n",
        "  print(result['label'], result['score'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVD3oirloXZ3",
        "outputId": "589bf186-c508-4963-ba69-1b52ede8a9d5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEGATIVE 0.9985528588294983\n",
            "POSITIVE 0.9998780488967896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking a look to the tokens\n",
        "tokens = tokenizer.tokenize(\"Today I'm feeling sleepy\")\n",
        "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "input_ids = tokenizer(\"Today I'm feeling sleepy\")\n",
        "\n",
        "print(f' Tokens: {tokens}')\n",
        "print(f'Token IDs: {tokens_ids}')\n",
        "print(f'Input IDs: {input_ids}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKp4i0y9q81k",
        "outputId": "386f4d8c-18c0-41e0-9ecd-0de456f69dc0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Tokens: ['today', 'i', \"'\", 'm', 'feeling', 'sleepy']\n",
            "Token IDs: [2651, 1045, 1005, 1049, 3110, 17056]\n",
            "Input IDs: {'input_ids': [101, 2651, 1045, 1005, 1049, 3110, 17056, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [\"Today I'm feeling sleepy\",\n",
        "           \"Today I'm feeling great\"]\n",
        "\n",
        "# Creating the batch\n",
        "batch = tokenizer(X_train, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Pythorch Classification\n",
        "with torch.no_grad():\n",
        "  outputs = model(**batch, labels=torch.tensor([1,0]))\n",
        "  print(outputs)\n",
        "  predictions = F.softmax(outputs.logits, dim=1)\n",
        "  print(predictions)\n",
        "  labels = torch.argmax(predictions, dim=1)\n",
        "  print(labels)\n",
        "  labels = [model.config.id2label[label_id] for label_id in labels.tolist()]\n",
        "  print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_fGehG4qcAp",
        "outputId": "14f49ba0-6231-4dd6-fb4b-5cc1ff76e3e1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SequenceClassifierOutput(loss=tensor(7.7752), logits=tensor([[ 3.5992, -2.9375],\n",
            "        [-4.3180,  4.6940]]), hidden_states=None, attentions=None)\n",
            "tensor([[9.9855e-01, 1.4472e-03],\n",
            "        [1.2192e-04, 9.9988e-01]])\n",
            "tensor([0, 1])\n",
            "['NEGATIVE', 'POSITIVE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Save and Loading"
      ],
      "metadata": {
        "id": "exM1dxiAvKze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory and Loading it\n",
        "save_directory = \"saved\"\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "model.save_pretrained(save_directory)\n",
        "\n",
        "# Loading the Model\n",
        "tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(save_directory)"
      ],
      "metadata": {
        "id": "DlrP7jVFvNfn"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Model Hub\n",
        "\n",
        "* https://huggingface.co/models"
      ],
      "metadata": {
        "id": "9hlHLuGgxSkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "texts = [\"Lack of support\",\n",
        "         \"Amazing team\",\n",
        "         \"Project delivered on time\",\n",
        "         \"Project delivered with a small delay\",\n",
        "         \"Project delayed\",\n",
        "         \"No opinion from my side\"]\n",
        "\n",
        "batch = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "print(batch)\n",
        "with torch.no_grad():\n",
        "  outputs = model(**batch)\n",
        "  labels_ids = torch.argmax(outputs.logits, dim=1)\n",
        "  print(labels_ids)\n",
        "  labels = [model.config.id2label[label_id] for label_id in labels_ids.tolist()]\n",
        "  print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq5zpeBnxcJC",
        "outputId": "326647c9-e40a-4e77-f953-8e4084aea3dd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    0,   574,  2990,     9,   323,     2,     1,     1],\n",
            "        [    0, 41710,   165,     2,     1,     1,     1,     1],\n",
            "        [    0, 33347,  2781,    15,    86,     2,     1,     1],\n",
            "        [    0, 33347,  2781,    19,    10,   650,  4646,     2],\n",
            "        [    0, 33347,  5943,     2,     1,     1,     1,     1],\n",
            "        [    0,  3084,  2979,    31,   127,   526,     2,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0],\n",
            "        [1, 1, 1, 1, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 0]])}\n",
            "tensor([0, 2, 2, 2, 0, 1])\n",
            "['negative', 'positive', 'positive', 'positive', 'negative', 'neutral']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Fine-Tunning With custom datasets"
      ],
      "metadata": {
        "id": "LK3kw2KtzpIR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g4UDhlrLz8u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KnBFbDROzsLp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}